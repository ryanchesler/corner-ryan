{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanchesler/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanchesler/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (135,204,274,417) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/ryanchesler/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (417) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../input/loan-default-prediction/train_v2.csv\")\n",
    "test = pd.read_csv(\"../input/loan-default-prediction/test_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"loss\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a345ae550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      95688\n",
       "2       1297\n",
       "1       1145\n",
       "3       1086\n",
       "4       1038\n",
       "5        685\n",
       "6        573\n",
       "7        565\n",
       "8        487\n",
       "10       316\n",
       "9        312\n",
       "11       234\n",
       "12       211\n",
       "13       188\n",
       "14       157\n",
       "15       140\n",
       "16       129\n",
       "17       123\n",
       "18       100\n",
       "20        83\n",
       "21        76\n",
       "19        73\n",
       "22        72\n",
       "23        48\n",
       "24        48\n",
       "27        46\n",
       "25        45\n",
       "100       35\n",
       "28        35\n",
       "29        33\n",
       "       ...  \n",
       "42         4\n",
       "84         4\n",
       "62         4\n",
       "94         4\n",
       "60         3\n",
       "78         3\n",
       "90         3\n",
       "58         3\n",
       "53         3\n",
       "74         2\n",
       "57         2\n",
       "56         2\n",
       "65         2\n",
       "70         2\n",
       "68         1\n",
       "55         1\n",
       "52         1\n",
       "81         1\n",
       "71         1\n",
       "72         1\n",
       "83         1\n",
       "73         1\n",
       "99         1\n",
       "95         1\n",
       "76         1\n",
       "92         1\n",
       "77         1\n",
       "85         1\n",
       "80         1\n",
       "63         1\n",
       "Name: loss, Length: 89, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#majority is zeros\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_target = target > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanchesler/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train['f528-f527'] = train['f528'] - train['f527']\n",
    "train['f528-f274'] = train['f528'] - train['f274']\n",
    "train['f527-f274'] = train['f527'] - train['f274']\n",
    "train['trial2'] = 5*train['f528'] - 4*train['f274'] - train['f527']\n",
    "train['hasnull'] = np.zeros(len(train))\n",
    "train['hasnull'][pd.isnull(train).any(axis=1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanchesler/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test['f528-f527'] = test['f528'] - test['f527']\n",
    "test['f528-f274'] = test['f528'] - test['f274']\n",
    "test['f527-f274'] = test['f527'] - test['f274']\n",
    "test['trial2'] = 5*test['f528'] - 4*test['f274'] - test['f527']\n",
    "test['hasnull'] = np.zeros(len(test))\n",
    "test['hasnull'][pd.isnull(test).any(axis=1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_feature_300 = ['f607', 'f723', 'f453', 'f452', 'f604', 'f454', 'f457', 'f456', 'f459', 'f163', 'f162', 'f164', 'f752', 'f769', 'f502', 'f510', 'f455', 'f512', 'f762', 'f761', 'f283', 'f688', 'f206', 'f42', 'f750', 'f606', 'f681', 'f683', 'f684', 'f685', 'f686', 'f687', 'f608', 'f505', 'f504', 'f469', 'f610', 'f549', 'f616', 'f615', 'f507', 'f758', 'f759', 'f420', 'f119', 'f299', 'f503', 'f115', 'f501', 'f500', 'f293', 'f757', 'f291', 'f113', 'f215', 'f214', 'f511', 'f192', 'f692', 'f691', 'f690', 'f697', 'f506', 'f592', 'f595', 'f550', 'f537', 'f534', 'f94', 'f530', 'f531', 'f198', 'f625', 'f749', 'f748', 'f538', 'f539', 'f644', 'f435', 'f345', 'f109', 'f346', 'f472', 'f105', 'f104', 'f103', 'f439', 'hasnull', 'f95', 'f184', 'f182', 'f224', 'f497', 'f188', 'f583', 'f581', 'f580', 'f585', 'f584', 'f521', 'f28', 'f633', 'f730', 'f736', 'f482', 'f483', 'f480', 'f481', 'f486', 'f487', 'f484', 'f485', 'f400', 'f207', 'f285', 'f323', 'f130', 'f131', 'f515', 'f137', 'f527', 'f335', 'f232', 'f33', 'f36', 'f48', 'f678', 'f568', 'f125', 'f722', 'f720', 'f120', 'f123', 'f724', 'f728', 'f129', 'f747', 'f554', 'f555', 'f557', 'f419', 'f551', 'f552', 'f415', 'f414', 'f558', 'f559', 'f124', 'f753', 'f325', 'f89', 'f321', 'f85', 'f84', 'f242', 'f83', 'f190', 'f675', 'f627', 'f528', 'f770', 'f152', 'f718', 'f719', 'f158', 'f389', 'f714', 'f712', 'f713', 'f710', 'f711', 'f547', 'f546', 'f90', 'f544', 'f543', 'f542', 'f541', 'f540', 'f460', 'f461', 'f99', 'f464', 'f466', 'f548', 'f317', 'f315', 'f252', 'f495', 'f494', 'f18', 'f496', 'f491', 'f490', 'f493', 'f492', 'f576', 'f709', 'f708', 'f387', 'f329', 'f347', 'f8', 'f703', 'f705', 'f704', 'f707', 'f706', 'f572', 'f570', 'f571', 'f262', 'f577', 'f574', 'f575', 'f114', 'f578', 'f579', 'f477', 'f476', 'f268', 'f470', 'f309', 'f666', 'f307', 'f301', 'f475', 'f78', 'f62', 'f396', 'f446', 'f447', 'f445', 'f174', 'f172', 'f173', 'f449', 'f569', 'f274', 'f565', 'f564', 'f567', 'f777', 'f561', 'f560', 'f772', 'f562', 'f52', 'f467', 'f93', 'f372', 'f355', 'f284', 'f754', 'f77']\n",
    "train = train.drop(tail_feature_300, axis = 1)\n",
    "test = test.drop(tail_feature_300, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns with weird dtypes or missing values. Dropping for now\n",
    "drop_cols = \"f138 f276 f277 f338 f390 f391 f626 f695 f698\".split()\n",
    "train = train.drop(drop_cols, axis = 1)\n",
    "test = test.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"binary_target\"] = bin_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index(\"id\")\n",
    "test = test.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"binary_dataset.csv\")\n",
    "test.to_csv(\"binary_testset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./binary_dataset.csv\")\n",
    "test = pd.read_csv(\"./binary_testset.csv\")\n",
    "bin_target = train[\"binary_target\"]\n",
    "train = train.drop(\"binary_target\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's binary_logloss: 0.189892\n",
      "[10]\tvalid_0's binary_logloss: 0.140868\n",
      "[15]\tvalid_0's binary_logloss: 0.110643\n",
      "[20]\tvalid_0's binary_logloss: 0.0895157\n",
      "[25]\tvalid_0's binary_logloss: 0.0748752\n",
      "[30]\tvalid_0's binary_logloss: 0.0640868\n",
      "[35]\tvalid_0's binary_logloss: 0.0559505\n",
      "[40]\tvalid_0's binary_logloss: 0.0498724\n",
      "[45]\tvalid_0's binary_logloss: 0.0453693\n",
      "[50]\tvalid_0's binary_logloss: 0.0416978\n",
      "[55]\tvalid_0's binary_logloss: 0.0387297\n",
      "[60]\tvalid_0's binary_logloss: 0.0364797\n",
      "[65]\tvalid_0's binary_logloss: 0.0347304\n",
      "[70]\tvalid_0's binary_logloss: 0.0332671\n",
      "[75]\tvalid_0's binary_logloss: 0.0321896\n",
      "[80]\tvalid_0's binary_logloss: 0.0313455\n",
      "[85]\tvalid_0's binary_logloss: 0.0303381\n",
      "[90]\tvalid_0's binary_logloss: 0.0297132\n",
      "[95]\tvalid_0's binary_logloss: 0.0292054\n",
      "[100]\tvalid_0's binary_logloss: 0.0287018\n",
      "[105]\tvalid_0's binary_logloss: 0.0282356\n",
      "[110]\tvalid_0's binary_logloss: 0.0279081\n",
      "[115]\tvalid_0's binary_logloss: 0.0275725\n",
      "[120]\tvalid_0's binary_logloss: 0.0272248\n",
      "[125]\tvalid_0's binary_logloss: 0.0270054\n",
      "[130]\tvalid_0's binary_logloss: 0.0267075\n",
      "[135]\tvalid_0's binary_logloss: 0.026496\n",
      "[140]\tvalid_0's binary_logloss: 0.0262372\n",
      "[145]\tvalid_0's binary_logloss: 0.0260979\n",
      "[150]\tvalid_0's binary_logloss: 0.0257942\n",
      "[155]\tvalid_0's binary_logloss: 0.0256633\n",
      "[160]\tvalid_0's binary_logloss: 0.0255298\n",
      "[165]\tvalid_0's binary_logloss: 0.0252721\n",
      "[170]\tvalid_0's binary_logloss: 0.0252369\n",
      "[175]\tvalid_0's binary_logloss: 0.0251992\n",
      "[180]\tvalid_0's binary_logloss: 0.0250668\n",
      "[185]\tvalid_0's binary_logloss: 0.0250137\n",
      "[190]\tvalid_0's binary_logloss: 0.02493\n",
      "[195]\tvalid_0's binary_logloss: 0.0248804\n",
      "[200]\tvalid_0's binary_logloss: 0.02481\n",
      "[205]\tvalid_0's binary_logloss: 0.0248267\n",
      "[210]\tvalid_0's binary_logloss: 0.0247163\n",
      "[215]\tvalid_0's binary_logloss: 0.0246544\n",
      "[220]\tvalid_0's binary_logloss: 0.0246363\n",
      "[225]\tvalid_0's binary_logloss: 0.0245469\n",
      "[230]\tvalid_0's binary_logloss: 0.0245367\n",
      "[235]\tvalid_0's binary_logloss: 0.0245053\n",
      "[240]\tvalid_0's binary_logloss: 0.0244169\n",
      "[245]\tvalid_0's binary_logloss: 0.0243577\n",
      "[250]\tvalid_0's binary_logloss: 0.0243175\n",
      "[255]\tvalid_0's binary_logloss: 0.0242512\n",
      "[260]\tvalid_0's binary_logloss: 0.024173\n",
      "[265]\tvalid_0's binary_logloss: 0.0241671\n",
      "[270]\tvalid_0's binary_logloss: 0.0241513\n",
      "[275]\tvalid_0's binary_logloss: 0.0241171\n",
      "[280]\tvalid_0's binary_logloss: 0.0240961\n",
      "[285]\tvalid_0's binary_logloss: 0.0241456\n",
      "[290]\tvalid_0's binary_logloss: 0.0240966\n",
      "[295]\tvalid_0's binary_logloss: 0.0240999\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's binary_logloss: 0.0240797\n",
      "0.9907561033420241\n",
      "0.951934927286172\n",
      "[[18969   143]\n",
      " [   52  1931]]\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's binary_logloss: 0.187512\n",
      "[10]\tvalid_0's binary_logloss: 0.139232\n",
      "[15]\tvalid_0's binary_logloss: 0.109507\n",
      "[20]\tvalid_0's binary_logloss: 0.0886122\n",
      "[25]\tvalid_0's binary_logloss: 0.0744212\n",
      "[30]\tvalid_0's binary_logloss: 0.0638624\n",
      "[35]\tvalid_0's binary_logloss: 0.0558029\n",
      "[40]\tvalid_0's binary_logloss: 0.0497882\n",
      "[45]\tvalid_0's binary_logloss: 0.0452212\n",
      "[50]\tvalid_0's binary_logloss: 0.0415109\n",
      "[55]\tvalid_0's binary_logloss: 0.0385598\n",
      "[60]\tvalid_0's binary_logloss: 0.0362288\n",
      "[65]\tvalid_0's binary_logloss: 0.0345194\n",
      "[70]\tvalid_0's binary_logloss: 0.0332112\n",
      "[75]\tvalid_0's binary_logloss: 0.0322118\n",
      "[80]\tvalid_0's binary_logloss: 0.0312351\n",
      "[85]\tvalid_0's binary_logloss: 0.0304822\n",
      "[90]\tvalid_0's binary_logloss: 0.0298926\n",
      "[95]\tvalid_0's binary_logloss: 0.0293753\n",
      "[100]\tvalid_0's binary_logloss: 0.0288526\n",
      "[105]\tvalid_0's binary_logloss: 0.028472\n",
      "[110]\tvalid_0's binary_logloss: 0.0281805\n",
      "[115]\tvalid_0's binary_logloss: 0.0278146\n",
      "[120]\tvalid_0's binary_logloss: 0.0274946\n",
      "[125]\tvalid_0's binary_logloss: 0.0272233\n",
      "[130]\tvalid_0's binary_logloss: 0.0268601\n",
      "[135]\tvalid_0's binary_logloss: 0.0266312\n",
      "[140]\tvalid_0's binary_logloss: 0.0263701\n",
      "[145]\tvalid_0's binary_logloss: 0.0261705\n",
      "[150]\tvalid_0's binary_logloss: 0.026099\n",
      "[155]\tvalid_0's binary_logloss: 0.0260585\n",
      "[160]\tvalid_0's binary_logloss: 0.0260347\n",
      "[165]\tvalid_0's binary_logloss: 0.0258992\n",
      "[170]\tvalid_0's binary_logloss: 0.0257066\n",
      "[175]\tvalid_0's binary_logloss: 0.0255414\n",
      "[180]\tvalid_0's binary_logloss: 0.025444\n",
      "[185]\tvalid_0's binary_logloss: 0.0253821\n",
      "[190]\tvalid_0's binary_logloss: 0.0253561\n",
      "[195]\tvalid_0's binary_logloss: 0.0252949\n",
      "[200]\tvalid_0's binary_logloss: 0.025223\n",
      "[205]\tvalid_0's binary_logloss: 0.0251627\n",
      "[210]\tvalid_0's binary_logloss: 0.0250003\n",
      "[215]\tvalid_0's binary_logloss: 0.0249767\n",
      "[220]\tvalid_0's binary_logloss: 0.0249671\n",
      "[225]\tvalid_0's binary_logloss: 0.0249369\n",
      "[230]\tvalid_0's binary_logloss: 0.024774\n",
      "[235]\tvalid_0's binary_logloss: 0.0247898\n",
      "[240]\tvalid_0's binary_logloss: 0.0247069\n",
      "[245]\tvalid_0's binary_logloss: 0.0246765\n",
      "[250]\tvalid_0's binary_logloss: 0.024647\n",
      "[255]\tvalid_0's binary_logloss: 0.0246401\n",
      "[260]\tvalid_0's binary_logloss: 0.0246311\n",
      "[265]\tvalid_0's binary_logloss: 0.0245726\n",
      "[270]\tvalid_0's binary_logloss: 0.0245044\n",
      "[275]\tvalid_0's binary_logloss: 0.0244379\n",
      "[280]\tvalid_0's binary_logloss: 0.0244198\n",
      "[285]\tvalid_0's binary_logloss: 0.0243827\n",
      "[290]\tvalid_0's binary_logloss: 0.0244251\n",
      "[295]\tvalid_0's binary_logloss: 0.0243148\n",
      "[300]\tvalid_0's binary_logloss: 0.0242787\n",
      "[305]\tvalid_0's binary_logloss: 0.0242606\n",
      "[310]\tvalid_0's binary_logloss: 0.0242677\n",
      "[315]\tvalid_0's binary_logloss: 0.0241967\n",
      "[320]\tvalid_0's binary_logloss: 0.0242143\n",
      "[325]\tvalid_0's binary_logloss: 0.0242263\n",
      "[330]\tvalid_0's binary_logloss: 0.0242197\n",
      "[335]\tvalid_0's binary_logloss: 0.0241619\n",
      "[340]\tvalid_0's binary_logloss: 0.0241905\n",
      "[345]\tvalid_0's binary_logloss: 0.0242015\n",
      "[350]\tvalid_0's binary_logloss: 0.0242403\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's binary_logloss: 0.0241542\n",
      "0.990755665118043\n",
      "0.9509680663816947\n",
      "[[19008   142]\n",
      " [   53  1891]]\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's binary_logloss: 0.185639\n",
      "[10]\tvalid_0's binary_logloss: 0.137871\n",
      "[15]\tvalid_0's binary_logloss: 0.1083\n",
      "[20]\tvalid_0's binary_logloss: 0.087968\n",
      "[25]\tvalid_0's binary_logloss: 0.0738342\n",
      "[30]\tvalid_0's binary_logloss: 0.0631853\n",
      "[35]\tvalid_0's binary_logloss: 0.0553556\n",
      "[40]\tvalid_0's binary_logloss: 0.0495637\n",
      "[45]\tvalid_0's binary_logloss: 0.045205\n",
      "[50]\tvalid_0's binary_logloss: 0.0417174\n",
      "[55]\tvalid_0's binary_logloss: 0.0389661\n",
      "[60]\tvalid_0's binary_logloss: 0.0370191\n",
      "[65]\tvalid_0's binary_logloss: 0.0352591\n",
      "[70]\tvalid_0's binary_logloss: 0.0338971\n",
      "[75]\tvalid_0's binary_logloss: 0.0328126\n",
      "[80]\tvalid_0's binary_logloss: 0.0318891\n",
      "[85]\tvalid_0's binary_logloss: 0.0311157\n",
      "[90]\tvalid_0's binary_logloss: 0.0306363\n",
      "[95]\tvalid_0's binary_logloss: 0.0300943\n",
      "[100]\tvalid_0's binary_logloss: 0.0297524\n",
      "[105]\tvalid_0's binary_logloss: 0.0293307\n",
      "[110]\tvalid_0's binary_logloss: 0.0289839\n",
      "[115]\tvalid_0's binary_logloss: 0.0285813\n",
      "[120]\tvalid_0's binary_logloss: 0.028404\n",
      "[125]\tvalid_0's binary_logloss: 0.0281947\n",
      "[130]\tvalid_0's binary_logloss: 0.0280678\n",
      "[135]\tvalid_0's binary_logloss: 0.0279274\n",
      "[140]\tvalid_0's binary_logloss: 0.0276234\n",
      "[145]\tvalid_0's binary_logloss: 0.0273609\n",
      "[150]\tvalid_0's binary_logloss: 0.0271961\n",
      "[155]\tvalid_0's binary_logloss: 0.0271689\n",
      "[160]\tvalid_0's binary_logloss: 0.027098\n",
      "[165]\tvalid_0's binary_logloss: 0.0269798\n",
      "[170]\tvalid_0's binary_logloss: 0.0267975\n",
      "[175]\tvalid_0's binary_logloss: 0.0267004\n",
      "[180]\tvalid_0's binary_logloss: 0.0265999\n",
      "[185]\tvalid_0's binary_logloss: 0.0266179\n",
      "[190]\tvalid_0's binary_logloss: 0.0265128\n",
      "[195]\tvalid_0's binary_logloss: 0.026453\n",
      "[200]\tvalid_0's binary_logloss: 0.0263294\n",
      "[205]\tvalid_0's binary_logloss: 0.0262728\n",
      "[210]\tvalid_0's binary_logloss: 0.0261404\n",
      "[215]\tvalid_0's binary_logloss: 0.0261476\n",
      "[220]\tvalid_0's binary_logloss: 0.0261453\n",
      "[225]\tvalid_0's binary_logloss: 0.0261715\n",
      "[230]\tvalid_0's binary_logloss: 0.0261183\n",
      "[235]\tvalid_0's binary_logloss: 0.0261384\n",
      "[240]\tvalid_0's binary_logloss: 0.02609\n",
      "[245]\tvalid_0's binary_logloss: 0.0260473\n",
      "[250]\tvalid_0's binary_logloss: 0.0261055\n",
      "[255]\tvalid_0's binary_logloss: 0.0260469\n",
      "[260]\tvalid_0's binary_logloss: 0.0260025\n",
      "[265]\tvalid_0's binary_logloss: 0.0260337\n",
      "[270]\tvalid_0's binary_logloss: 0.0259837\n",
      "[275]\tvalid_0's binary_logloss: 0.0259788\n",
      "[280]\tvalid_0's binary_logloss: 0.0259914\n",
      "[285]\tvalid_0's binary_logloss: 0.0259409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290]\tvalid_0's binary_logloss: 0.0259664\n",
      "[295]\tvalid_0's binary_logloss: 0.0258628\n",
      "[300]\tvalid_0's binary_logloss: 0.0258762\n",
      "[305]\tvalid_0's binary_logloss: 0.0259258\n",
      "[310]\tvalid_0's binary_logloss: 0.0259324\n",
      "[315]\tvalid_0's binary_logloss: 0.0259078\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's binary_logloss: 0.0258558\n",
      "0.9899497487437185\n",
      "0.9467604218985435\n",
      "[[18997   177]\n",
      " [   35  1885]]\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's binary_logloss: 0.191282\n",
      "[10]\tvalid_0's binary_logloss: 0.14202\n",
      "[15]\tvalid_0's binary_logloss: 0.111598\n",
      "[20]\tvalid_0's binary_logloss: 0.090504\n",
      "[25]\tvalid_0's binary_logloss: 0.0756192\n",
      "[30]\tvalid_0's binary_logloss: 0.0646607\n",
      "[35]\tvalid_0's binary_logloss: 0.0564779\n",
      "[40]\tvalid_0's binary_logloss: 0.0505426\n",
      "[45]\tvalid_0's binary_logloss: 0.0461163\n",
      "[50]\tvalid_0's binary_logloss: 0.0424299\n",
      "[55]\tvalid_0's binary_logloss: 0.0395317\n",
      "[60]\tvalid_0's binary_logloss: 0.0372701\n",
      "[65]\tvalid_0's binary_logloss: 0.0356094\n",
      "[70]\tvalid_0's binary_logloss: 0.034254\n",
      "[75]\tvalid_0's binary_logloss: 0.0330469\n",
      "[80]\tvalid_0's binary_logloss: 0.0323008\n",
      "[85]\tvalid_0's binary_logloss: 0.0315701\n",
      "[90]\tvalid_0's binary_logloss: 0.030929\n",
      "[95]\tvalid_0's binary_logloss: 0.0303643\n",
      "[100]\tvalid_0's binary_logloss: 0.0299151\n",
      "[105]\tvalid_0's binary_logloss: 0.0294685\n",
      "[110]\tvalid_0's binary_logloss: 0.0291389\n",
      "[115]\tvalid_0's binary_logloss: 0.028889\n",
      "[120]\tvalid_0's binary_logloss: 0.0287125\n",
      "[125]\tvalid_0's binary_logloss: 0.0284666\n",
      "[130]\tvalid_0's binary_logloss: 0.0282427\n",
      "[135]\tvalid_0's binary_logloss: 0.028039\n",
      "[140]\tvalid_0's binary_logloss: 0.0277305\n",
      "[145]\tvalid_0's binary_logloss: 0.027554\n",
      "[150]\tvalid_0's binary_logloss: 0.0274181\n",
      "[155]\tvalid_0's binary_logloss: 0.0272759\n",
      "[160]\tvalid_0's binary_logloss: 0.0272018\n",
      "[165]\tvalid_0's binary_logloss: 0.0271171\n",
      "[170]\tvalid_0's binary_logloss: 0.0270094\n",
      "[175]\tvalid_0's binary_logloss: 0.0269111\n",
      "[180]\tvalid_0's binary_logloss: 0.026772\n",
      "[185]\tvalid_0's binary_logloss: 0.0266859\n",
      "[190]\tvalid_0's binary_logloss: 0.0265559\n",
      "[195]\tvalid_0's binary_logloss: 0.026574\n",
      "[200]\tvalid_0's binary_logloss: 0.0264613\n",
      "[205]\tvalid_0's binary_logloss: 0.0264265\n",
      "[210]\tvalid_0's binary_logloss: 0.0264238\n",
      "[215]\tvalid_0's binary_logloss: 0.026402\n",
      "[220]\tvalid_0's binary_logloss: 0.0263165\n",
      "[225]\tvalid_0's binary_logloss: 0.0262971\n",
      "[230]\tvalid_0's binary_logloss: 0.0262236\n",
      "[235]\tvalid_0's binary_logloss: 0.0260815\n",
      "[240]\tvalid_0's binary_logloss: 0.0260591\n",
      "[245]\tvalid_0's binary_logloss: 0.0260116\n",
      "[250]\tvalid_0's binary_logloss: 0.0259653\n",
      "[255]\tvalid_0's binary_logloss: 0.0258873\n",
      "[260]\tvalid_0's binary_logloss: 0.0259112\n",
      "[265]\tvalid_0's binary_logloss: 0.0258535\n",
      "[270]\tvalid_0's binary_logloss: 0.0257732\n",
      "[275]\tvalid_0's binary_logloss: 0.0257577\n",
      "[280]\tvalid_0's binary_logloss: 0.0257617\n",
      "[285]\tvalid_0's binary_logloss: 0.0257045\n",
      "[290]\tvalid_0's binary_logloss: 0.0256432\n",
      "[295]\tvalid_0's binary_logloss: 0.0255752\n",
      "[300]\tvalid_0's binary_logloss: 0.0255904\n",
      "[305]\tvalid_0's binary_logloss: 0.0256133\n",
      "[310]\tvalid_0's binary_logloss: 0.0255641\n",
      "[315]\tvalid_0's binary_logloss: 0.0255785\n",
      "[320]\tvalid_0's binary_logloss: 0.0255574\n",
      "[325]\tvalid_0's binary_logloss: 0.0255117\n",
      "[330]\tvalid_0's binary_logloss: 0.0254994\n",
      "[335]\tvalid_0's binary_logloss: 0.0255349\n",
      "[340]\tvalid_0's binary_logloss: 0.0255311\n",
      "[345]\tvalid_0's binary_logloss: 0.0255072\n",
      "[350]\tvalid_0's binary_logloss: 0.0254637\n",
      "[355]\tvalid_0's binary_logloss: 0.0254819\n",
      "[360]\tvalid_0's binary_logloss: 0.025513\n",
      "[365]\tvalid_0's binary_logloss: 0.0255415\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid_0's binary_logloss: 0.0254535\n",
      "0.9904712240447521\n",
      "0.951035322777101\n",
      "[[18941   138]\n",
      " [   63  1952]]\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's binary_logloss: 0.187221\n",
      "[10]\tvalid_0's binary_logloss: 0.139698\n",
      "[15]\tvalid_0's binary_logloss: 0.109759\n",
      "[20]\tvalid_0's binary_logloss: 0.0890932\n",
      "[25]\tvalid_0's binary_logloss: 0.0745553\n",
      "[30]\tvalid_0's binary_logloss: 0.0638235\n",
      "[35]\tvalid_0's binary_logloss: 0.0559572\n",
      "[40]\tvalid_0's binary_logloss: 0.0497816\n",
      "[45]\tvalid_0's binary_logloss: 0.0455232\n",
      "[50]\tvalid_0's binary_logloss: 0.041745\n",
      "[55]\tvalid_0's binary_logloss: 0.0388748\n",
      "[60]\tvalid_0's binary_logloss: 0.0366263\n",
      "[65]\tvalid_0's binary_logloss: 0.0347925\n",
      "[70]\tvalid_0's binary_logloss: 0.033344\n",
      "[75]\tvalid_0's binary_logloss: 0.0322685\n",
      "[80]\tvalid_0's binary_logloss: 0.0312864\n",
      "[85]\tvalid_0's binary_logloss: 0.0304942\n",
      "[90]\tvalid_0's binary_logloss: 0.0297553\n",
      "[95]\tvalid_0's binary_logloss: 0.0292269\n",
      "[100]\tvalid_0's binary_logloss: 0.0288216\n",
      "[105]\tvalid_0's binary_logloss: 0.0283562\n",
      "[110]\tvalid_0's binary_logloss: 0.0279624\n",
      "[115]\tvalid_0's binary_logloss: 0.0276535\n",
      "[120]\tvalid_0's binary_logloss: 0.0273587\n",
      "[125]\tvalid_0's binary_logloss: 0.027166\n",
      "[130]\tvalid_0's binary_logloss: 0.0270843\n",
      "[135]\tvalid_0's binary_logloss: 0.0268898\n",
      "[140]\tvalid_0's binary_logloss: 0.0266082\n",
      "[145]\tvalid_0's binary_logloss: 0.0263409\n",
      "[150]\tvalid_0's binary_logloss: 0.0261863\n",
      "[155]\tvalid_0's binary_logloss: 0.0260862\n",
      "[160]\tvalid_0's binary_logloss: 0.0260049\n",
      "[165]\tvalid_0's binary_logloss: 0.0259138\n",
      "[170]\tvalid_0's binary_logloss: 0.0256969\n",
      "[175]\tvalid_0's binary_logloss: 0.0254328\n",
      "[180]\tvalid_0's binary_logloss: 0.0253257\n",
      "[185]\tvalid_0's binary_logloss: 0.0251802\n",
      "[190]\tvalid_0's binary_logloss: 0.0250748\n",
      "[195]\tvalid_0's binary_logloss: 0.0250035\n",
      "[200]\tvalid_0's binary_logloss: 0.0249853\n",
      "[205]\tvalid_0's binary_logloss: 0.0249403\n",
      "[210]\tvalid_0's binary_logloss: 0.024954\n",
      "[215]\tvalid_0's binary_logloss: 0.0248864\n",
      "[220]\tvalid_0's binary_logloss: 0.0248654\n",
      "[225]\tvalid_0's binary_logloss: 0.0248527\n",
      "[230]\tvalid_0's binary_logloss: 0.0247723\n",
      "[235]\tvalid_0's binary_logloss: 0.0245968\n",
      "[240]\tvalid_0's binary_logloss: 0.0245891\n",
      "[245]\tvalid_0's binary_logloss: 0.0245938\n",
      "[250]\tvalid_0's binary_logloss: 0.0245695\n",
      "[255]\tvalid_0's binary_logloss: 0.0245258\n",
      "[260]\tvalid_0's binary_logloss: 0.0245408\n",
      "[265]\tvalid_0's binary_logloss: 0.0244925\n",
      "[270]\tvalid_0's binary_logloss: 0.0244828\n",
      "[275]\tvalid_0's binary_logloss: 0.0243899\n",
      "[280]\tvalid_0's binary_logloss: 0.0243164\n",
      "[285]\tvalid_0's binary_logloss: 0.0243558\n",
      "[290]\tvalid_0's binary_logloss: 0.0243088\n",
      "[295]\tvalid_0's binary_logloss: 0.0242697\n",
      "[300]\tvalid_0's binary_logloss: 0.0242377\n",
      "[305]\tvalid_0's binary_logloss: 0.024194\n",
      "[310]\tvalid_0's binary_logloss: 0.0242253\n",
      "[315]\tvalid_0's binary_logloss: 0.0242325\n",
      "[320]\tvalid_0's binary_logloss: 0.0242387\n",
      "[325]\tvalid_0's binary_logloss: 0.0242373\n",
      "Early stopping, best iteration is:\n",
      "[305]\tvalid_0's binary_logloss: 0.024194\n",
      "0.9903290035081066\n",
      "0.9483282674772037\n",
      "[[19018   155]\n",
      " [   49  1872]]\n"
     ]
    }
   ],
   "source": [
    "num_folds = 5\n",
    "kf = KFold(n_splits = num_folds, shuffle = True, random_state = 42)\n",
    "bin_oof = np.zeros(shape = train.shape[0])\n",
    "test_oof = np.zeros(shape = test.shape[0])\n",
    "for train_index, val_index in kf.split(train):\n",
    "    train_X = train.iloc[train_index]\n",
    "    val_X = train.iloc[val_index]\n",
    "    train_y = bin_target.iloc[train_index]\n",
    "    val_y = bin_target.iloc[val_index]\n",
    "    lgb_train = lgb.Dataset(train_X, train_y)\n",
    "    lgb_eval = lgb.Dataset(val_X, val_y)\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 5\n",
    "    }\n",
    "    gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=2000,\n",
    "                valid_sets=lgb_eval,\n",
    "               early_stopping_rounds=20,\n",
    "               verbose_eval = 5)\n",
    "\n",
    "    y_pred = gbm.predict(val_X, num_iteration=gbm.best_iteration)\n",
    "    y_test_pred = gbm.predict(test, num_iteration=gbm.best_iteration)\n",
    "    print(accuracy_score(y_pred>.5, val_y))\n",
    "    print(f1_score(y_pred>.5, val_y))\n",
    "    print(confusion_matrix(val_y, y_pred>.5))\n",
    "    bin_oof[val_index] = y_pred\n",
    "    test_oof += y_test_pred/num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94982311026957"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(bin_target, bin_oof > .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error on negative predictions\n",
    "neg_loss = mean_absolute_error(np.zeros(shape = (train[bin_oof< .5].shape[0])), target[bin_oof< .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.058331713007972"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error from positive predictions. Not a good metric, just a sanity check\n",
    "mean_absolute_error(np.zeros(shape = (train[bin_oof> .5].shape[0])), target[bin_oof> .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train = train.iloc[bin_oof>.5]\n",
    "pos_test = test.iloc[test_oof>.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_target = np.log1p(target.iloc[bin_oof>.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's l1: 0.674162\n",
      "[10]\tvalid_0's l1: 0.6321\n",
      "[15]\tvalid_0's l1: 0.603308\n",
      "[20]\tvalid_0's l1: 0.580315\n",
      "[25]\tvalid_0's l1: 0.56377\n",
      "[30]\tvalid_0's l1: 0.550456\n",
      "[35]\tvalid_0's l1: 0.540374\n",
      "[40]\tvalid_0's l1: 0.533265\n",
      "[45]\tvalid_0's l1: 0.527039\n",
      "[50]\tvalid_0's l1: 0.522205\n",
      "[55]\tvalid_0's l1: 0.519292\n",
      "[60]\tvalid_0's l1: 0.516599\n",
      "[65]\tvalid_0's l1: 0.513494\n",
      "[70]\tvalid_0's l1: 0.510556\n",
      "[75]\tvalid_0's l1: 0.508645\n",
      "[80]\tvalid_0's l1: 0.505869\n",
      "[85]\tvalid_0's l1: 0.504393\n",
      "[90]\tvalid_0's l1: 0.502709\n",
      "[95]\tvalid_0's l1: 0.502116\n",
      "[100]\tvalid_0's l1: 0.501168\n",
      "[105]\tvalid_0's l1: 0.500414\n",
      "[110]\tvalid_0's l1: 0.498975\n",
      "[115]\tvalid_0's l1: 0.497649\n",
      "[120]\tvalid_0's l1: 0.4968\n",
      "[125]\tvalid_0's l1: 0.495791\n",
      "[130]\tvalid_0's l1: 0.495026\n",
      "[135]\tvalid_0's l1: 0.494072\n",
      "[140]\tvalid_0's l1: 0.493945\n",
      "[145]\tvalid_0's l1: 0.493354\n",
      "[150]\tvalid_0's l1: 0.492527\n",
      "[155]\tvalid_0's l1: 0.491789\n",
      "[160]\tvalid_0's l1: 0.491336\n",
      "[165]\tvalid_0's l1: 0.490783\n",
      "[170]\tvalid_0's l1: 0.490216\n",
      "[175]\tvalid_0's l1: 0.490004\n",
      "[180]\tvalid_0's l1: 0.489872\n",
      "[185]\tvalid_0's l1: 0.489732\n",
      "[190]\tvalid_0's l1: 0.48968\n",
      "[195]\tvalid_0's l1: 0.489496\n",
      "[200]\tvalid_0's l1: 0.489186\n",
      "[205]\tvalid_0's l1: 0.489351\n",
      "[210]\tvalid_0's l1: 0.488621\n",
      "[215]\tvalid_0's l1: 0.488262\n",
      "[220]\tvalid_0's l1: 0.488267\n",
      "[225]\tvalid_0's l1: 0.488451\n",
      "[230]\tvalid_0's l1: 0.488911\n",
      "[235]\tvalid_0's l1: 0.488928\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's l1: 0.488262\n",
      "4.137273678481121\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's l1: 0.689994\n",
      "[10]\tvalid_0's l1: 0.647325\n",
      "[15]\tvalid_0's l1: 0.617048\n",
      "[20]\tvalid_0's l1: 0.594184\n",
      "[25]\tvalid_0's l1: 0.577699\n",
      "[30]\tvalid_0's l1: 0.56642\n",
      "[35]\tvalid_0's l1: 0.557857\n",
      "[40]\tvalid_0's l1: 0.550147\n",
      "[45]\tvalid_0's l1: 0.544999\n",
      "[50]\tvalid_0's l1: 0.539646\n",
      "[55]\tvalid_0's l1: 0.535564\n",
      "[60]\tvalid_0's l1: 0.532383\n",
      "[65]\tvalid_0's l1: 0.528887\n",
      "[70]\tvalid_0's l1: 0.525986\n",
      "[75]\tvalid_0's l1: 0.522867\n",
      "[80]\tvalid_0's l1: 0.521886\n",
      "[85]\tvalid_0's l1: 0.519842\n",
      "[90]\tvalid_0's l1: 0.517494\n",
      "[95]\tvalid_0's l1: 0.515988\n",
      "[100]\tvalid_0's l1: 0.515201\n",
      "[105]\tvalid_0's l1: 0.513777\n",
      "[110]\tvalid_0's l1: 0.511513\n",
      "[115]\tvalid_0's l1: 0.510262\n",
      "[120]\tvalid_0's l1: 0.509545\n",
      "[125]\tvalid_0's l1: 0.508463\n",
      "[130]\tvalid_0's l1: 0.507552\n",
      "[135]\tvalid_0's l1: 0.507235\n",
      "[140]\tvalid_0's l1: 0.506514\n",
      "[145]\tvalid_0's l1: 0.505863\n",
      "[150]\tvalid_0's l1: 0.504609\n",
      "[155]\tvalid_0's l1: 0.502994\n",
      "[160]\tvalid_0's l1: 0.5022\n",
      "[165]\tvalid_0's l1: 0.501603\n",
      "[170]\tvalid_0's l1: 0.501504\n",
      "[175]\tvalid_0's l1: 0.501376\n",
      "[180]\tvalid_0's l1: 0.501017\n",
      "[185]\tvalid_0's l1: 0.500014\n",
      "[190]\tvalid_0's l1: 0.499655\n",
      "[195]\tvalid_0's l1: 0.499677\n",
      "[200]\tvalid_0's l1: 0.499176\n",
      "[205]\tvalid_0's l1: 0.498449\n",
      "[210]\tvalid_0's l1: 0.498598\n",
      "[215]\tvalid_0's l1: 0.498327\n",
      "[220]\tvalid_0's l1: 0.498167\n",
      "[225]\tvalid_0's l1: 0.498218\n",
      "[230]\tvalid_0's l1: 0.498147\n",
      "[235]\tvalid_0's l1: 0.498162\n",
      "[240]\tvalid_0's l1: 0.498173\n",
      "[245]\tvalid_0's l1: 0.498143\n",
      "[250]\tvalid_0's l1: 0.497937\n",
      "[255]\tvalid_0's l1: 0.497702\n",
      "[260]\tvalid_0's l1: 0.497419\n",
      "[265]\tvalid_0's l1: 0.4974\n",
      "[270]\tvalid_0's l1: 0.49736\n",
      "[275]\tvalid_0's l1: 0.497266\n",
      "[280]\tvalid_0's l1: 0.497138\n",
      "[285]\tvalid_0's l1: 0.496499\n",
      "[290]\tvalid_0's l1: 0.496436\n",
      "[295]\tvalid_0's l1: 0.496373\n",
      "[300]\tvalid_0's l1: 0.496318\n",
      "[305]\tvalid_0's l1: 0.496242\n",
      "[310]\tvalid_0's l1: 0.49619\n",
      "[315]\tvalid_0's l1: 0.496097\n",
      "[320]\tvalid_0's l1: 0.496203\n",
      "[325]\tvalid_0's l1: 0.496196\n",
      "[330]\tvalid_0's l1: 0.495866\n",
      "[335]\tvalid_0's l1: 0.495971\n",
      "[340]\tvalid_0's l1: 0.495905\n",
      "[345]\tvalid_0's l1: 0.495927\n",
      "[350]\tvalid_0's l1: 0.495873\n",
      "[355]\tvalid_0's l1: 0.495874\n",
      "[360]\tvalid_0's l1: 0.495904\n",
      "[365]\tvalid_0's l1: 0.4958\n",
      "[370]\tvalid_0's l1: 0.49574\n",
      "[375]\tvalid_0's l1: 0.495768\n",
      "[380]\tvalid_0's l1: 0.495625\n",
      "[385]\tvalid_0's l1: 0.495655\n",
      "[390]\tvalid_0's l1: 0.495841\n",
      "[395]\tvalid_0's l1: 0.495871\n",
      "Early stopping, best iteration is:\n",
      "[379]\tvalid_0's l1: 0.495505\n",
      "4.399008330502239\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's l1: 0.673221\n",
      "[10]\tvalid_0's l1: 0.631865\n",
      "[15]\tvalid_0's l1: 0.602604\n",
      "[20]\tvalid_0's l1: 0.581076\n",
      "[25]\tvalid_0's l1: 0.565562\n",
      "[30]\tvalid_0's l1: 0.553728\n",
      "[35]\tvalid_0's l1: 0.5458\n",
      "[40]\tvalid_0's l1: 0.539019\n",
      "[45]\tvalid_0's l1: 0.53336\n",
      "[50]\tvalid_0's l1: 0.529277\n",
      "[55]\tvalid_0's l1: 0.525495\n",
      "[60]\tvalid_0's l1: 0.521992\n",
      "[65]\tvalid_0's l1: 0.519231\n",
      "[70]\tvalid_0's l1: 0.516395\n",
      "[75]\tvalid_0's l1: 0.514936\n",
      "[80]\tvalid_0's l1: 0.512991\n",
      "[85]\tvalid_0's l1: 0.511421\n",
      "[90]\tvalid_0's l1: 0.509658\n",
      "[95]\tvalid_0's l1: 0.508213\n",
      "[100]\tvalid_0's l1: 0.507156\n",
      "[105]\tvalid_0's l1: 0.506423\n",
      "[110]\tvalid_0's l1: 0.506194\n",
      "[115]\tvalid_0's l1: 0.505365\n",
      "[120]\tvalid_0's l1: 0.505071\n",
      "[125]\tvalid_0's l1: 0.504204\n",
      "[130]\tvalid_0's l1: 0.503907\n",
      "[135]\tvalid_0's l1: 0.502898\n",
      "[140]\tvalid_0's l1: 0.502597\n",
      "[145]\tvalid_0's l1: 0.502762\n",
      "[150]\tvalid_0's l1: 0.502117\n",
      "[155]\tvalid_0's l1: 0.501829\n",
      "[160]\tvalid_0's l1: 0.501662\n",
      "[165]\tvalid_0's l1: 0.501537\n",
      "[170]\tvalid_0's l1: 0.500735\n",
      "[175]\tvalid_0's l1: 0.500371\n",
      "[180]\tvalid_0's l1: 0.499724\n",
      "[185]\tvalid_0's l1: 0.499286\n",
      "[190]\tvalid_0's l1: 0.498865\n",
      "[195]\tvalid_0's l1: 0.499071\n",
      "[200]\tvalid_0's l1: 0.498757\n",
      "[205]\tvalid_0's l1: 0.498516\n",
      "[210]\tvalid_0's l1: 0.498578\n",
      "[215]\tvalid_0's l1: 0.498797\n",
      "[220]\tvalid_0's l1: 0.498705\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's l1: 0.498418\n",
      "4.4315613735785435\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's l1: 0.675832\n",
      "[10]\tvalid_0's l1: 0.636425\n",
      "[15]\tvalid_0's l1: 0.608513\n",
      "[20]\tvalid_0's l1: 0.587431\n",
      "[25]\tvalid_0's l1: 0.570823\n",
      "[30]\tvalid_0's l1: 0.558118\n",
      "[35]\tvalid_0's l1: 0.546817\n",
      "[40]\tvalid_0's l1: 0.53743\n",
      "[45]\tvalid_0's l1: 0.530726\n",
      "[50]\tvalid_0's l1: 0.525393\n",
      "[55]\tvalid_0's l1: 0.520347\n",
      "[60]\tvalid_0's l1: 0.516106\n",
      "[65]\tvalid_0's l1: 0.511237\n",
      "[70]\tvalid_0's l1: 0.507622\n",
      "[75]\tvalid_0's l1: 0.504087\n",
      "[80]\tvalid_0's l1: 0.501766\n",
      "[85]\tvalid_0's l1: 0.499986\n",
      "[90]\tvalid_0's l1: 0.497966\n",
      "[95]\tvalid_0's l1: 0.495656\n",
      "[100]\tvalid_0's l1: 0.494744\n",
      "[105]\tvalid_0's l1: 0.49353\n",
      "[110]\tvalid_0's l1: 0.49175\n",
      "[115]\tvalid_0's l1: 0.490856\n",
      "[120]\tvalid_0's l1: 0.49042\n",
      "[125]\tvalid_0's l1: 0.489238\n",
      "[130]\tvalid_0's l1: 0.488173\n",
      "[135]\tvalid_0's l1: 0.487204\n",
      "[140]\tvalid_0's l1: 0.486186\n",
      "[145]\tvalid_0's l1: 0.485248\n",
      "[150]\tvalid_0's l1: 0.484462\n",
      "[155]\tvalid_0's l1: 0.483623\n",
      "[160]\tvalid_0's l1: 0.483647\n",
      "[165]\tvalid_0's l1: 0.483447\n",
      "[170]\tvalid_0's l1: 0.482885\n",
      "[175]\tvalid_0's l1: 0.482027\n",
      "[180]\tvalid_0's l1: 0.481202\n",
      "[185]\tvalid_0's l1: 0.481431\n",
      "[190]\tvalid_0's l1: 0.481424\n",
      "[195]\tvalid_0's l1: 0.48092\n",
      "[200]\tvalid_0's l1: 0.481037\n",
      "[205]\tvalid_0's l1: 0.480533\n",
      "[210]\tvalid_0's l1: 0.480468\n",
      "[215]\tvalid_0's l1: 0.480279\n",
      "[220]\tvalid_0's l1: 0.479956\n",
      "[225]\tvalid_0's l1: 0.479398\n",
      "[230]\tvalid_0's l1: 0.479346\n",
      "[235]\tvalid_0's l1: 0.479246\n",
      "[240]\tvalid_0's l1: 0.479148\n",
      "[245]\tvalid_0's l1: 0.478902\n",
      "[250]\tvalid_0's l1: 0.478738\n",
      "[255]\tvalid_0's l1: 0.478458\n",
      "[260]\tvalid_0's l1: 0.47829\n",
      "[265]\tvalid_0's l1: 0.478568\n",
      "[270]\tvalid_0's l1: 0.478462\n",
      "[275]\tvalid_0's l1: 0.478581\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's l1: 0.478256\n",
      "4.467949498995424\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's l1: 0.674151\n",
      "[10]\tvalid_0's l1: 0.635752\n",
      "[15]\tvalid_0's l1: 0.608546\n",
      "[20]\tvalid_0's l1: 0.588071\n",
      "[25]\tvalid_0's l1: 0.572341\n",
      "[30]\tvalid_0's l1: 0.56016\n",
      "[35]\tvalid_0's l1: 0.551483\n",
      "[40]\tvalid_0's l1: 0.543683\n",
      "[45]\tvalid_0's l1: 0.537814\n",
      "[50]\tvalid_0's l1: 0.532698\n",
      "[55]\tvalid_0's l1: 0.528049\n",
      "[60]\tvalid_0's l1: 0.524726\n",
      "[65]\tvalid_0's l1: 0.522506\n",
      "[70]\tvalid_0's l1: 0.518885\n",
      "[75]\tvalid_0's l1: 0.516738\n",
      "[80]\tvalid_0's l1: 0.514406\n",
      "[85]\tvalid_0's l1: 0.512458\n",
      "[90]\tvalid_0's l1: 0.511187\n",
      "[95]\tvalid_0's l1: 0.510398\n",
      "[100]\tvalid_0's l1: 0.50882\n",
      "[105]\tvalid_0's l1: 0.507275\n",
      "[110]\tvalid_0's l1: 0.50677\n",
      "[115]\tvalid_0's l1: 0.505359\n",
      "[120]\tvalid_0's l1: 0.504678\n",
      "[125]\tvalid_0's l1: 0.503698\n",
      "[130]\tvalid_0's l1: 0.503014\n",
      "[135]\tvalid_0's l1: 0.502555\n",
      "[140]\tvalid_0's l1: 0.501847\n",
      "[145]\tvalid_0's l1: 0.501924\n",
      "[150]\tvalid_0's l1: 0.501131\n",
      "[155]\tvalid_0's l1: 0.50117\n",
      "[160]\tvalid_0's l1: 0.501156\n",
      "[165]\tvalid_0's l1: 0.500861\n",
      "[170]\tvalid_0's l1: 0.500295\n",
      "[175]\tvalid_0's l1: 0.499868\n",
      "[180]\tvalid_0's l1: 0.499749\n",
      "[185]\tvalid_0's l1: 0.499348\n",
      "[190]\tvalid_0's l1: 0.499386\n",
      "[195]\tvalid_0's l1: 0.49973\n",
      "[200]\tvalid_0's l1: 0.499435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205]\tvalid_0's l1: 0.499402\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's l1: 0.499332\n",
      "4.354860977147143\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = num_folds, shuffle = True, random_state = 42)\n",
    "oof = np.zeros(shape = pos_train.shape[0])\n",
    "test_reg_oof = np.zeros(shape = pos_test.shape[0])\n",
    "pos_loss = 0\n",
    "for train_index, val_index in kf.split(pos_train):\n",
    "    train_X = pos_train.iloc[train_index]\n",
    "    val_X = pos_train.iloc[val_index]\n",
    "    train_y = reg_target.iloc[train_index]\n",
    "    val_y = reg_target.iloc[val_index]\n",
    "    lgb_train = lgb.Dataset(train_X, train_y)\n",
    "    lgb_eval = lgb.Dataset(val_X, val_y)\n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': {'mae'},\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.9,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0\n",
    "            }\n",
    "    gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=2000,\n",
    "                valid_sets=lgb_eval,\n",
    "               early_stopping_rounds=20,\n",
    "               verbose_eval = 5)\n",
    "\n",
    "    y_pred = np.expm1(gbm.predict(val_X, num_iteration=gbm.best_iteration))\n",
    "    y_test_pred = np.expm1(gbm.predict(pos_test, num_iteration=gbm.best_iteration))\n",
    "    pos_loss += mean_absolute_error(y_pred, np.expm1(val_y))/num_folds\n",
    "    print(mean_absolute_error(y_pred, np.expm1(val_y)))\n",
    "    oof[val_index] = y_pred\n",
    "    test_reg_oof += y_test_pred/num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 31  15  41  19   5   3  19   7   8  25  43   9   4  11   4   5   4   5\n",
      "   9   5   7  16  11   3   3   2  10   7   0   0   0   0  10   4  17   4\n",
      "  14   6  14  20   9   6   6   2   6  10   6  17   1  12  12  11   8  14\n",
      "   4   4 209  23   9  10  20  13   8   0  19  18   9   9   5  11   9   0\n",
      "   1  42  10  10   0   0  16   7   3   5   0   0   2   3  10   5   1   0\n",
      "  45   9   2   0   0  18  10  18   9   6  10  11   8  35  13   8   6   2\n",
      "   4   3   9  16  10   5   3   0   0   0  12   6  11   1   0   0   3  12\n",
      "   3   3   0   0   0   1  14  12   8   2   3   0   0  16  19   8   2   0\n",
      "   0   0   7  10  16  12  34   4   8  13   8   7  11  15   8   1   6  20\n",
      "   6   4  11   0   8   4   2   0  17  25  21   3   0   5   0   0   0   1\n",
      "   2   6   5   1   5   1   0   0   0   3   6   9  20   7   0   0   0   1\n",
      "  18   7  11   8   6   0   0   0   7   9  33  26  27  13  21  11  16  14\n",
      "   9   6   3   8  15  12  14   1   0   0   1   9   3   1   0   0   0   3\n",
      "   7   3   1   0   5  12   5   2   0   0   9   4   2   1   0   4  11  30\n",
      "  33  29   8   4  17  11   5   5   2   4   6   7   7   5   3   8   0   3\n",
      "   5   2  13   7  10   0   4   4   1  13   9   9   8   8   0   3  13   9\n",
      "  52  29  22   0   3   6  11   7  17  12   1   7   9  15  21   9  11  11\n",
      "   9   7  12   7  48  21  35  12   0   5   7  10  12  12  15   0   6   8\n",
      "  15   5   2  14   3   0   7   5   6  16  13  15  20  27   4   4   7  10\n",
      "  18   5  10  16  12  13  14   2  14  14   0  17   0  10   0  21   0  18\n",
      "   4  70  10   2  32   5   4  11   4  13  16  11   9   5  17   8  11   7\n",
      "   0   9   0  14   0   0   4  16  17  17   0   4   9   7  83  45  55   2\n",
      "   6  19   2  11   8  27  17   0  15   8  22   7   7   5  10   8  20  12\n",
      "  14   7   5   2   1   8  16  22  34   5   5   6   7   8  17  12  11  10\n",
      "   2  69  49  40  31   9  15   2   6   2   4  24  27  24  14  12   7  37\n",
      " 179   9  36  14   6   7   2   9  10  10   2   3   4   9   3   0   0   0\n",
      "   6   8   3   7   2   7   9   0   3   8   9  16   5  10  12  18  15   0\n",
      "   4  14   4   9  22   9  15  11   9   3   0   4  49   3   4   6   6   7\n",
      "  36  37  35  83  55  83  49]\n",
      "['id', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f9', 'f10', 'f13', 'f14', 'f15', 'f16', 'f17', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f29', 'f30', 'f31', 'f32', 'f34', 'f35', 'f37', 'f38', 'f39', 'f40', 'f41', 'f43', 'f44', 'f45', 'f46', 'f47', 'f49', 'f50', 'f51', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f79', 'f80', 'f81', 'f82', 'f86', 'f87', 'f88', 'f91', 'f92', 'f96', 'f97', 'f98', 'f100', 'f101', 'f102', 'f106', 'f107', 'f108', 'f110', 'f111', 'f112', 'f116', 'f117', 'f118', 'f121', 'f122', 'f126', 'f127', 'f128', 'f132', 'f133', 'f134', 'f135', 'f136', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f153', 'f154', 'f155', 'f156', 'f157', 'f159', 'f160', 'f161', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f183', 'f185', 'f186', 'f187', 'f189', 'f191', 'f193', 'f194', 'f195', 'f196', 'f197', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f263', 'f264', 'f265', 'f266', 'f267', 'f269', 'f270', 'f271', 'f272', 'f273', 'f275', 'f278', 'f279', 'f280', 'f281', 'f282', 'f286', 'f287', 'f288', 'f289', 'f290', 'f292', 'f294', 'f295', 'f296', 'f297', 'f298', 'f300', 'f302', 'f303', 'f304', 'f305', 'f306', 'f308', 'f310', 'f311', 'f312', 'f313', 'f314', 'f316', 'f318', 'f319', 'f320', 'f322', 'f324', 'f326', 'f327', 'f328', 'f330', 'f331', 'f332', 'f333', 'f334', 'f336', 'f337', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f388', 'f392', 'f393', 'f394', 'f395', 'f397', 'f398', 'f399', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f416', 'f417', 'f418', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f436', 'f437', 'f438', 'f440', 'f441', 'f442', 'f443', 'f444', 'f448', 'f450', 'f451', 'f458', 'f465', 'f468', 'f471', 'f478', 'f479', 'f488', 'f489', 'f498', 'f499', 'f508', 'f509', 'f513', 'f514', 'f516', 'f517', 'f518', 'f519', 'f520', 'f522', 'f523', 'f524', 'f525', 'f526', 'f529', 'f532', 'f533', 'f535', 'f536', 'f545', 'f553', 'f556', 'f563', 'f566', 'f573', 'f582', 'f586', 'f587', 'f588', 'f589', 'f590', 'f591', 'f593', 'f594', 'f596', 'f597', 'f598', 'f599', 'f600', 'f601', 'f609', 'f611', 'f612', 'f613', 'f614', 'f617', 'f618', 'f619', 'f620', 'f621', 'f622', 'f623', 'f624', 'f628', 'f629', 'f630', 'f631', 'f632', 'f634', 'f635', 'f636', 'f637', 'f638', 'f639', 'f640', 'f641', 'f642', 'f643', 'f645', 'f646', 'f647', 'f648', 'f649', 'f650', 'f651', 'f652', 'f653', 'f654', 'f655', 'f656', 'f657', 'f658', 'f659', 'f660', 'f661', 'f662', 'f663', 'f664', 'f665', 'f667', 'f668', 'f669', 'f670', 'f671', 'f672', 'f673', 'f674', 'f676', 'f677', 'f679', 'f680', 'f682', 'f689', 'f693', 'f694', 'f696', 'f699', 'f700', 'f701', 'f702', 'f715', 'f716', 'f717', 'f721', 'f725', 'f726', 'f727', 'f729', 'f731', 'f732', 'f733', 'f734', 'f735', 'f737', 'f738', 'f739', 'f740', 'f741', 'f742', 'f743', 'f744', 'f745', 'f746', 'f751', 'f755', 'f756', 'f760', 'f763', 'f764', 'f765', 'f766', 'f767', 'f768', 'f771', 'f773', 'f774', 'f775', 'f776', 'f778', 'f528-f527', 'f528-f274', 'f527-f274', 'trial2']\n"
     ]
    }
   ],
   "source": [
    "print(gbm.feature_importance())\n",
    "print(gbm.feature_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4387247026967302\n"
     ]
    }
   ],
   "source": [
    "print((pos_loss*len(bin_oof[bin_oof>.5])+neg_loss*len(bin_oof[bin_oof<.5]))/len(bin_oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_oof[test_oof>.5] = test_reg_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../input/loan-default-prediction/sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"loss\"] = test_oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"second_sub.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_target = np.log1p(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's l1: 0.256465\n",
      "[10]\tvalid_0's l1: 0.210177\n",
      "[15]\tvalid_0's l1: 0.175535\n",
      "[20]\tvalid_0's l1: 0.148614\n",
      "[25]\tvalid_0's l1: 0.128892\n",
      "[30]\tvalid_0's l1: 0.115208\n",
      "[35]\tvalid_0's l1: 0.104687\n",
      "[40]\tvalid_0's l1: 0.0966735\n",
      "[45]\tvalid_0's l1: 0.0909567\n",
      "[50]\tvalid_0's l1: 0.0860399\n",
      "[55]\tvalid_0's l1: 0.0827513\n",
      "[60]\tvalid_0's l1: 0.0799957\n",
      "[65]\tvalid_0's l1: 0.0778195\n",
      "[70]\tvalid_0's l1: 0.076162\n",
      "[75]\tvalid_0's l1: 0.0747058\n",
      "[80]\tvalid_0's l1: 0.0737627\n",
      "[85]\tvalid_0's l1: 0.0730006\n",
      "[90]\tvalid_0's l1: 0.07219\n",
      "[95]\tvalid_0's l1: 0.071638\n",
      "[100]\tvalid_0's l1: 0.0711864\n",
      "[105]\tvalid_0's l1: 0.0709023\n",
      "[110]\tvalid_0's l1: 0.0704653\n",
      "[115]\tvalid_0's l1: 0.0702014\n",
      "[120]\tvalid_0's l1: 0.0699518\n",
      "[125]\tvalid_0's l1: 0.0698323\n",
      "[130]\tvalid_0's l1: 0.069557\n",
      "[135]\tvalid_0's l1: 0.0694602\n",
      "[140]\tvalid_0's l1: 0.0694384\n",
      "[145]\tvalid_0's l1: 0.0695719\n",
      "[150]\tvalid_0's l1: 0.0695107\n",
      "[155]\tvalid_0's l1: 0.0694418\n",
      "[160]\tvalid_0's l1: 0.0693728\n",
      "[165]\tvalid_0's l1: 0.06939\n",
      "[170]\tvalid_0's l1: 0.0693559\n",
      "[175]\tvalid_0's l1: 0.0691782\n",
      "[180]\tvalid_0's l1: 0.069159\n",
      "[185]\tvalid_0's l1: 0.0690934\n",
      "[190]\tvalid_0's l1: 0.0690749\n",
      "[195]\tvalid_0's l1: 0.0690924\n",
      "[200]\tvalid_0's l1: 0.0690222\n",
      "[205]\tvalid_0's l1: 0.0690873\n",
      "[210]\tvalid_0's l1: 0.069098\n",
      "[215]\tvalid_0's l1: 0.0689427\n",
      "[220]\tvalid_0's l1: 0.0688779\n",
      "[225]\tvalid_0's l1: 0.0688501\n",
      "[230]\tvalid_0's l1: 0.0688179\n",
      "[235]\tvalid_0's l1: 0.068876\n",
      "[240]\tvalid_0's l1: 0.0687399\n",
      "[245]\tvalid_0's l1: 0.0686332\n",
      "[250]\tvalid_0's l1: 0.0686362\n",
      "[255]\tvalid_0's l1: 0.0686135\n",
      "[260]\tvalid_0's l1: 0.0685758\n",
      "[265]\tvalid_0's l1: 0.0685565\n",
      "[270]\tvalid_0's l1: 0.0685042\n",
      "[275]\tvalid_0's l1: 0.0684116\n",
      "[280]\tvalid_0's l1: 0.0684238\n",
      "[285]\tvalid_0's l1: 0.0684574\n",
      "[290]\tvalid_0's l1: 0.0685075\n",
      "[295]\tvalid_0's l1: 0.0684718\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's l1: 0.0684053\n",
      "0.4956540030922857\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's l1: 0.253673\n",
      "[10]\tvalid_0's l1: 0.207653\n",
      "[15]\tvalid_0's l1: 0.173729\n",
      "[20]\tvalid_0's l1: 0.148288\n",
      "[25]\tvalid_0's l1: 0.129269\n",
      "[30]\tvalid_0's l1: 0.115201\n",
      "[35]\tvalid_0's l1: 0.105058\n",
      "[40]\tvalid_0's l1: 0.0975006\n",
      "[45]\tvalid_0's l1: 0.0912588\n",
      "[50]\tvalid_0's l1: 0.0863125\n",
      "[55]\tvalid_0's l1: 0.0826976\n",
      "[60]\tvalid_0's l1: 0.079896\n",
      "[65]\tvalid_0's l1: 0.0772104\n",
      "[70]\tvalid_0's l1: 0.0754522\n",
      "[75]\tvalid_0's l1: 0.0742258\n",
      "[80]\tvalid_0's l1: 0.0729607\n",
      "[85]\tvalid_0's l1: 0.0721124\n",
      "[90]\tvalid_0's l1: 0.0715055\n",
      "[95]\tvalid_0's l1: 0.0705193\n",
      "[100]\tvalid_0's l1: 0.0701456\n",
      "[105]\tvalid_0's l1: 0.0698106\n",
      "[110]\tvalid_0's l1: 0.0693105\n",
      "[115]\tvalid_0's l1: 0.069089\n",
      "[120]\tvalid_0's l1: 0.0687662\n",
      "[125]\tvalid_0's l1: 0.0685992\n",
      "[130]\tvalid_0's l1: 0.0684061\n",
      "[135]\tvalid_0's l1: 0.0682824\n",
      "[140]\tvalid_0's l1: 0.068032\n",
      "[145]\tvalid_0's l1: 0.0679367\n",
      "[150]\tvalid_0's l1: 0.0678299\n",
      "[155]\tvalid_0's l1: 0.0676558\n",
      "[160]\tvalid_0's l1: 0.0677421\n",
      "[165]\tvalid_0's l1: 0.0676153\n",
      "[170]\tvalid_0's l1: 0.0676088\n",
      "[175]\tvalid_0's l1: 0.0675444\n",
      "[180]\tvalid_0's l1: 0.0673264\n",
      "[185]\tvalid_0's l1: 0.0672329\n",
      "[190]\tvalid_0's l1: 0.0671577\n",
      "[195]\tvalid_0's l1: 0.0671097\n",
      "[200]\tvalid_0's l1: 0.0671054\n",
      "[205]\tvalid_0's l1: 0.0670694\n",
      "[210]\tvalid_0's l1: 0.0670573\n",
      "[215]\tvalid_0's l1: 0.06708\n",
      "[220]\tvalid_0's l1: 0.0670763\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's l1: 0.0670505\n",
      "0.48043277813148866\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's l1: 0.255396\n",
      "[10]\tvalid_0's l1: 0.209584\n",
      "[15]\tvalid_0's l1: 0.175166\n",
      "[20]\tvalid_0's l1: 0.148712\n",
      "[25]\tvalid_0's l1: 0.129349\n",
      "[30]\tvalid_0's l1: 0.115447\n",
      "[35]\tvalid_0's l1: 0.105087\n",
      "[40]\tvalid_0's l1: 0.096992\n",
      "[45]\tvalid_0's l1: 0.0910384\n",
      "[50]\tvalid_0's l1: 0.0864448\n",
      "[55]\tvalid_0's l1: 0.0831124\n",
      "[60]\tvalid_0's l1: 0.0802728\n",
      "[65]\tvalid_0's l1: 0.0778861\n",
      "[70]\tvalid_0's l1: 0.0761079\n",
      "[75]\tvalid_0's l1: 0.0745748\n",
      "[80]\tvalid_0's l1: 0.0734521\n",
      "[85]\tvalid_0's l1: 0.072709\n",
      "[90]\tvalid_0's l1: 0.071988\n",
      "[95]\tvalid_0's l1: 0.0714544\n",
      "[100]\tvalid_0's l1: 0.0708976\n",
      "[105]\tvalid_0's l1: 0.070494\n",
      "[110]\tvalid_0's l1: 0.0700452\n",
      "[115]\tvalid_0's l1: 0.069935\n",
      "[120]\tvalid_0's l1: 0.0696311\n",
      "[125]\tvalid_0's l1: 0.0695436\n",
      "[130]\tvalid_0's l1: 0.0693736\n",
      "[135]\tvalid_0's l1: 0.0692492\n",
      "[140]\tvalid_0's l1: 0.0691158\n",
      "[145]\tvalid_0's l1: 0.0691099\n",
      "[150]\tvalid_0's l1: 0.0689721\n",
      "[155]\tvalid_0's l1: 0.0689316\n",
      "[160]\tvalid_0's l1: 0.0686531\n",
      "[165]\tvalid_0's l1: 0.0684035\n",
      "[170]\tvalid_0's l1: 0.0683858\n",
      "[175]\tvalid_0's l1: 0.0682776\n",
      "[180]\tvalid_0's l1: 0.0682966\n",
      "[185]\tvalid_0's l1: 0.0683029\n",
      "[190]\tvalid_0's l1: 0.0682715\n",
      "[195]\tvalid_0's l1: 0.0681398\n",
      "[200]\tvalid_0's l1: 0.0681125\n",
      "[205]\tvalid_0's l1: 0.0680608\n",
      "[210]\tvalid_0's l1: 0.0680545\n",
      "[215]\tvalid_0's l1: 0.0679591\n",
      "[220]\tvalid_0's l1: 0.0679478\n",
      "[225]\tvalid_0's l1: 0.0679281\n",
      "[230]\tvalid_0's l1: 0.0679034\n",
      "[235]\tvalid_0's l1: 0.0679184\n",
      "[240]\tvalid_0's l1: 0.0679149\n",
      "[245]\tvalid_0's l1: 0.06793\n",
      "[250]\tvalid_0's l1: 0.0679214\n",
      "[255]\tvalid_0's l1: 0.0678697\n",
      "[260]\tvalid_0's l1: 0.0678632\n",
      "[265]\tvalid_0's l1: 0.0678946\n",
      "[270]\tvalid_0's l1: 0.0678608\n",
      "[275]\tvalid_0's l1: 0.067762\n",
      "[280]\tvalid_0's l1: 0.0676906\n",
      "[285]\tvalid_0's l1: 0.0676815\n",
      "[290]\tvalid_0's l1: 0.0677153\n",
      "[295]\tvalid_0's l1: 0.0676781\n",
      "[300]\tvalid_0's l1: 0.0676901\n",
      "[305]\tvalid_0's l1: 0.0676836\n",
      "Early stopping, best iteration is:\n",
      "[286]\tvalid_0's l1: 0.0676729\n",
      "0.4846384861504481\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's l1: 0.257129\n",
      "[10]\tvalid_0's l1: 0.210032\n",
      "[15]\tvalid_0's l1: 0.17503\n",
      "[20]\tvalid_0's l1: 0.148601\n",
      "[25]\tvalid_0's l1: 0.129368\n",
      "[30]\tvalid_0's l1: 0.115614\n",
      "[35]\tvalid_0's l1: 0.105271\n",
      "[40]\tvalid_0's l1: 0.096598\n",
      "[45]\tvalid_0's l1: 0.0906529\n",
      "[50]\tvalid_0's l1: 0.0862686\n",
      "[55]\tvalid_0's l1: 0.0826564\n",
      "[60]\tvalid_0's l1: 0.0799501\n",
      "[65]\tvalid_0's l1: 0.0773705\n",
      "[70]\tvalid_0's l1: 0.0757205\n",
      "[75]\tvalid_0's l1: 0.0746431\n",
      "[80]\tvalid_0's l1: 0.0737405\n",
      "[85]\tvalid_0's l1: 0.073076\n",
      "[90]\tvalid_0's l1: 0.0724056\n",
      "[95]\tvalid_0's l1: 0.0719037\n",
      "[100]\tvalid_0's l1: 0.0713386\n",
      "[105]\tvalid_0's l1: 0.0708812\n",
      "[110]\tvalid_0's l1: 0.0705689\n",
      "[115]\tvalid_0's l1: 0.0702853\n",
      "[120]\tvalid_0's l1: 0.0698504\n",
      "[125]\tvalid_0's l1: 0.069688\n",
      "[130]\tvalid_0's l1: 0.069556\n",
      "[135]\tvalid_0's l1: 0.0694649\n",
      "[140]\tvalid_0's l1: 0.0692221\n",
      "[145]\tvalid_0's l1: 0.069175\n",
      "[150]\tvalid_0's l1: 0.0688776\n",
      "[155]\tvalid_0's l1: 0.0688164\n",
      "[160]\tvalid_0's l1: 0.0687966\n",
      "[165]\tvalid_0's l1: 0.0686605\n",
      "[170]\tvalid_0's l1: 0.0686115\n",
      "[175]\tvalid_0's l1: 0.0686193\n",
      "[180]\tvalid_0's l1: 0.0685799\n",
      "[185]\tvalid_0's l1: 0.068501\n",
      "[190]\tvalid_0's l1: 0.06841\n",
      "[195]\tvalid_0's l1: 0.0683471\n",
      "[200]\tvalid_0's l1: 0.0683811\n",
      "[205]\tvalid_0's l1: 0.068245\n",
      "[210]\tvalid_0's l1: 0.0680385\n",
      "[215]\tvalid_0's l1: 0.0680044\n",
      "[220]\tvalid_0's l1: 0.0679938\n",
      "[225]\tvalid_0's l1: 0.067974\n",
      "[230]\tvalid_0's l1: 0.0679554\n",
      "[235]\tvalid_0's l1: 0.0678489\n",
      "[240]\tvalid_0's l1: 0.0677741\n",
      "[245]\tvalid_0's l1: 0.0677716\n",
      "[250]\tvalid_0's l1: 0.0677747\n",
      "[255]\tvalid_0's l1: 0.0677818\n",
      "[260]\tvalid_0's l1: 0.0678018\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's l1: 0.0677504\n",
      "0.48376970632434785\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[5]\tvalid_0's l1: 0.253355\n",
      "[10]\tvalid_0's l1: 0.207928\n",
      "[15]\tvalid_0's l1: 0.173999\n",
      "[20]\tvalid_0's l1: 0.147146\n",
      "[25]\tvalid_0's l1: 0.127951\n",
      "[30]\tvalid_0's l1: 0.114241\n",
      "[35]\tvalid_0's l1: 0.103706\n",
      "[40]\tvalid_0's l1: 0.0958307\n",
      "[45]\tvalid_0's l1: 0.0897258\n",
      "[50]\tvalid_0's l1: 0.0848246\n",
      "[55]\tvalid_0's l1: 0.0814314\n",
      "[60]\tvalid_0's l1: 0.0786031\n",
      "[65]\tvalid_0's l1: 0.0761603\n",
      "[70]\tvalid_0's l1: 0.0743272\n",
      "[75]\tvalid_0's l1: 0.0729655\n",
      "[80]\tvalid_0's l1: 0.07161\n",
      "[85]\tvalid_0's l1: 0.0708355\n",
      "[90]\tvalid_0's l1: 0.0701859\n",
      "[95]\tvalid_0's l1: 0.0694629\n",
      "[100]\tvalid_0's l1: 0.0688863\n",
      "[105]\tvalid_0's l1: 0.0684792\n",
      "[110]\tvalid_0's l1: 0.0680999\n",
      "[115]\tvalid_0's l1: 0.0678167\n",
      "[120]\tvalid_0's l1: 0.0675591\n",
      "[125]\tvalid_0's l1: 0.067448\n",
      "[130]\tvalid_0's l1: 0.0671706\n",
      "[135]\tvalid_0's l1: 0.0669199\n",
      "[140]\tvalid_0's l1: 0.0667282\n",
      "[145]\tvalid_0's l1: 0.0666234\n",
      "[150]\tvalid_0's l1: 0.066546\n",
      "[155]\tvalid_0's l1: 0.0665371\n",
      "[160]\tvalid_0's l1: 0.0664453\n",
      "[165]\tvalid_0's l1: 0.0662938\n",
      "[170]\tvalid_0's l1: 0.0663754\n",
      "[175]\tvalid_0's l1: 0.0663686\n",
      "[180]\tvalid_0's l1: 0.0661627\n",
      "[185]\tvalid_0's l1: 0.066014\n",
      "[190]\tvalid_0's l1: 0.0659271\n",
      "[195]\tvalid_0's l1: 0.065811\n",
      "[200]\tvalid_0's l1: 0.0658586\n",
      "[205]\tvalid_0's l1: 0.0658677\n",
      "[210]\tvalid_0's l1: 0.0659225\n",
      "[215]\tvalid_0's l1: 0.0659377\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's l1: 0.065811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46528949999426417\n"
     ]
    }
   ],
   "source": [
    "#retrying as a single pipeline\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits = num_folds, shuffle = True, random_state = 42)\n",
    "oof = np.zeros(shape = train.shape[0])\n",
    "test_reg_oof = np.zeros(shape = test.shape[0])\n",
    "loss = 0\n",
    "for train_index, val_index in kf.split(train):\n",
    "    train_X = train.iloc[train_index]\n",
    "    val_X = train.iloc[val_index]\n",
    "    train_y = reg_target.iloc[train_index]\n",
    "    val_y = reg_target.iloc[val_index]\n",
    "    lgb_train = lgb.Dataset(train_X, train_y)\n",
    "    lgb_eval = lgb.Dataset(val_X, val_y)\n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': {'mae'},\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.9,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': 0\n",
    "            }\n",
    "    gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=2000,\n",
    "                valid_sets=lgb_eval,\n",
    "               early_stopping_rounds=20,\n",
    "               verbose_eval = 5)\n",
    "\n",
    "    y_pred = np.expm1(gbm.predict(val_X, num_iteration=gbm.best_iteration))\n",
    "    y_test_pred = np.expm1(gbm.predict(test, num_iteration=gbm.best_iteration))\n",
    "    loss += mean_absolute_error(y_pred, np.expm1(val_y))/num_folds\n",
    "    print(mean_absolute_error(y_pred, np.expm1(val_y)))\n",
    "    oof[val_index] = y_pred\n",
    "    test_reg_oof += y_test_pred/num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reg_oof[test_reg_oof < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../input/loan-default-prediction/sampleSubmission.csv\")\n",
    "\n",
    "sub[\"loss\"] = test_reg_oof\n",
    "\n",
    "sub.to_csv(\"full_pipe_sub_filtered_negs.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
